{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "def testing_model(model, test_loader, device = torch.device('cpu')):\n",
    "    \"\"\"\n",
    "    Evaluate the model on the validation set.\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    model.to(device)\n",
    "    correct, total = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for features, targets in test_loader:\n",
    "            features = features.to(device, dtype=torch.float32)\n",
    "            targets = targets.to(device, dtype=torch.long)\n",
    "\n",
    "            outputs = model(features)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total += targets.size(0)\n",
    "            correct += (predicted == targets).sum().item()\n",
    "\n",
    "    test_accuracy = 100 * correct / total\n",
    "    return test_accuracy\n",
    "\n",
    "def predict(model, data, device = torch.device('cpu')):\n",
    "    with torch.no_grad():\n",
    "        features = data[0].to(device, dtype=torch.float32)  # Shape: [77]\n",
    "        features = features.unsqueeze(0) # Shape: [1, 77] (add channel dim)\n",
    "        outputs = model(features)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "    return predicted.item() + 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataset import CustomDataset\n",
    "import pandas as pd\n",
    "\n",
    "test_1 = pd.read_csv(\"scaled_test_1.csv\", index_col=0)\n",
    "test_2 = pd.read_csv(\"scaled_test_2.csv\", index_col=0)\n",
    "test_3 = pd.read_csv(\"scaled_test_3.csv\", index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "key_length\n",
       "19    232\n",
       "23    232\n",
       "21    227\n",
       "8     222\n",
       "12    222\n",
       "16    221\n",
       "6     220\n",
       "17    218\n",
       "22    217\n",
       "18    215\n",
       "7     213\n",
       "9     205\n",
       "5     203\n",
       "25    202\n",
       "10    202\n",
       "11    200\n",
       "24    200\n",
       "13    198\n",
       "15    198\n",
       "14    193\n",
       "20    191\n",
       "4     185\n",
       "3     184\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_1['key_length'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset_1 = CustomDataset(test_1)\n",
    "test_dataset_2 = CustomDataset(test_2)\n",
    "test_dataset_3 = CustomDataset(test_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "BATCH_SIZE=128\n",
    "test_loader_1 = DataLoader(test_dataset_1, batch_size=BATCH_SIZE, shuffle=False)\n",
    "test_loader_2 = DataLoader(test_dataset_2, batch_size=BATCH_SIZE, shuffle=False)\n",
    "test_loader_3 = DataLoader(test_dataset_3, batch_size=BATCH_SIZE, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from model import KeyLengthCNN\n",
    "num_classes = len(test_dataset_1[0][0])\n",
    "model = KeyLengthCNN(input_size=num_classes)\n",
    "model.load_state_dict(torch.load('best_model.pth', weights_only=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing on 4800 samples whose length is smaller than 300: \n",
      "95.021%\n",
      "Testing on 4800 samples whose length is between 300 and 399: \n",
      "98.750%\n",
      "Testing on 9648 samples whose length is greater or equal to 400: \n",
      "99.109%\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f'Testing on {len(test_1)} samples whose length is smaller than 300: \\n{testing_model(model, test_loader_1, device):.3f}%')\n",
    "print(f'Testing on {len(test_2)} samples whose length is between 300 and 399: \\n{testing_model(model, test_loader_2, device):.3f}%')\n",
    "print(f'Testing on {len(test_3)} samples whose length is greater or equal to 400: \\n{testing_model(model, test_loader_3, device):.3f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from extract_features import extract_features\n",
    "import pandas as pd\n",
    "from dataset import rescale_dataset\n",
    "from viginere import encrypt_vigenere\n",
    "from utils import clean_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"\"\"Accepted presentations will not be published in any proceedings, \n",
    "however, viewgraphs and other materials will be reproduced for \n",
    "seminar attendees.\n",
    "\n",
    "ABSTRACTS: Authors should submit a one page abstract and/or videotape to:\n",
    "\n",
    "     Robert Lipman\n",
    "     Naval Surface Warfare Center, Carderock Division\n",
    "     Code 2042\n",
    "     Bethesda, Maryland  20084-5000\n",
    "\n",
    "     VOICE (301) 227-3618;  FAX (301) 227-5753  \"\"\"\n",
    "\n",
    "\n",
    "key = 'PHAMVIETGIANG'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "266"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = clean_text(text)\n",
    "len(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tải StandardScaler cho twist_columns từ scalers\\standard_scaler_twist.pkl\n",
      "Tải MinMaxScaler cho other_columns từ scalers\\minmax_scaler_other.pkl\n"
     ]
    }
   ],
   "source": [
    "ciphertext = encrypt_vigenere(text, key)\n",
    "data = extract_features(ciphertext)\n",
    "data['key_length'] = 0\n",
    "rescaled_data = rescale_dataset(pd.DataFrame([data]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "input = CustomDataset(rescaled_data)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-4.7115e-01,  1.2339e-01, -6.2426e-01,  1.3451e-01, -9.0393e-01,\n",
       "        -9.2706e-03, -1.1989e+00, -8.8036e-01,  6.3266e-01, -4.6220e-01,\n",
       "        -7.1804e-01, -2.4463e+00, -1.0428e+00, -8.4077e-01, -1.0697e+00,\n",
       "        -1.1073e+00, -7.7100e-01, -7.2687e-01, -3.9380e-01, -3.4512e-01,\n",
       "        -3.0878e-01,  1.6293e+00,  1.5068e+00,  1.3707e+00, -3.7831e-01,\n",
       "         3.8849e-01, -5.1888e-01,  5.5127e-01, -5.8641e-01,  6.8659e-01,\n",
       "        -5.0939e-01, -4.9747e-01,  1.0724e+00, -4.1848e-01,  8.9442e-01,\n",
       "        -1.9152e+00,  6.4339e-01,  2.3724e-01, -4.9416e-02, -3.3252e-01,\n",
       "         2.2863e-01, -3.4236e-01,  2.4062e-01,  1.0228e-03,  4.7158e-02,\n",
       "        -2.1078e-01,  2.8974e-01,  0.0000e+00,  2.2000e-01,  0.0000e+00,\n",
       "         6.6000e-02,  3.8871e-02,  3.7970e-01,  2.1053e-01,  3.9012e-02,\n",
       "         4.1739e-02,  3.8483e-02,  4.1371e-02,  3.5359e-02,  4.5691e-02,\n",
       "         4.3423e-02,  3.4291e-02,  3.8893e-02,  4.2208e-02,  6.4411e-02,\n",
       "         3.5088e-02,  3.5022e-02,  4.0411e-02,  3.2773e-02,  4.9613e-02,\n",
       "         3.8751e-02,  3.2692e-02,  3.6075e-02,  3.2687e-02,  2.8590e-02,\n",
       "         4.7475e-02,  2.8364e-02])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = predict(model, input, device=device)\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13, 'PHAMVIETGIANG')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(key), key "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(key) == result"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
